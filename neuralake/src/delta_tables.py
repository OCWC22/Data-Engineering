"""
Delta Lake table operations with ACID guarantees.

This module implements Neuralink-style Delta Lake patterns including:
- ACID transactional operations
- Time travel queries  
- Schema evolution
- High-performance batch and streaming operations
"""
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional, Union

import polars as pl
import pyarrow as pa
from deltalake import DeltaTable, write_deltalake

from delta_config import (
    get_delta_storage_options,
    get_delta_table_uri,
    get_delta_write_options,
    initialize_delta_environment
)

logger = logging.getLogger(__name__)


class NeuralakeDeltaTable:
    """
    Production-grade Delta Lake table wrapper with Neuralink patterns.
    
    Provides ACID transactions, time travel, and schema evolution
    for high-performance data operations.
    """
    
    def __init__(self, table_name: str, bucket: str = "neuralake-bucket"):
        """Initialize Delta table.
        
        Args:
            table_name: Name of the Delta table
            bucket: S3 bucket name
        """
        self.table_name = table_name
        self.bucket = bucket
        self.uri = get_delta_table_uri(table_name, bucket)
        self.storage_options = get_delta_storage_options()
        
        # Initialize Delta environment
        initialize_delta_environment()
        
        # Try to load existing table, None if doesn't exist
        self._delta_table: Optional[DeltaTable] = None
        self._load_table()
    
    def _load_table(self) -> None:
        """Load existing Delta table if it exists."""
        try:
            self._delta_table = DeltaTable(self.uri, storage_options=self.storage_options)
            logger.info(f"âœ… Loaded existing Delta table: {self.table_name}")
        except Exception as e:
            logger.info(f"ðŸ“ Delta table {self.table_name} not found (will be created): {e}")
            self._delta_table = None
    
    @property
    def exists(self) -> bool:
        """Check if table exists."""
        return self._delta_table is not None
    
    @property 
    def version(self) -> Optional[int]:
        """Get current table version."""
        return self._delta_table.version() if self._delta_table else None
    
    @property
    def schema(self) -> Optional[pa.Schema]:
        """Get table schema."""
        return self._delta_table.schema().to_pyarrow() if self._delta_table else None
    
    def create_table(
        self,
        data: Union[pl.DataFrame, pa.Table],
        partition_by: Optional[List[str]] = None,
        mode: str = "error"
    ) -> None:
        """Create new Delta table with initial data.
        
        Args:
            data: Initial data as Polars DataFrame or PyArrow Table
            partition_by: Optional list of columns to partition by
            mode: Write mode ('error', 'ignore', 'overwrite')
        """
        if self.exists and mode == "error":
            raise ValueError(f"Table {self.table_name} already exists")
        
        # Convert Polars to PyArrow if needed
        if isinstance(data, pl.DataFrame):
            arrow_table = data.to_arrow()
        else:
            arrow_table = data
        
        # Write options
        write_options = get_delta_write_options(
            mode="overwrite" if mode == "overwrite" else "error",
            partition_by=partition_by
        )
        
        logger.info(f"ðŸš€ Creating Delta table {self.table_name} with {len(arrow_table)} rows")
        
        # Create the table
        write_deltalake(
            self.uri,
            arrow_table,
            **write_options
        )
        
        # Reload table reference
        self._load_table()
        
        logger.info(f"âœ… Delta table {self.table_name} created (version {self.version})")
    
    def insert(
        self,
        data: Union[pl.DataFrame, pa.Table],
        mode: str = "append"
    ) -> None:
        """Insert data with ACID guarantees.
        
        Args:
            data: Data to insert as Polars DataFrame or PyArrow Table
            mode: Write mode ('append', 'overwrite')
        """
        if not self.exists:
            raise ValueError(f"Table {self.table_name} does not exist. Use create_table() first.")
        
        # Convert Polars to PyArrow if needed
        if isinstance(data, pl.DataFrame):
            arrow_table = data.to_arrow()
        else:
            arrow_table = data
        
        # Write options with schema merging for flexibility
        write_options = get_delta_write_options(mode=mode, schema_mode="merge")
        
        logger.info(f"ðŸ’¾ Inserting {len(arrow_table)} rows into {self.table_name}")
        
        # Perform atomic write
        write_deltalake(
            self.uri,
            arrow_table,
            **write_options
        )
        
        # Reload table to get new version
        self._load_table()
        
        logger.info(f"âœ… Insert complete (version {self.version})")
    
    def query(
        self,
        columns: Optional[List[str]] = None,
        filters: Optional[List] = None,
        version: Optional[int] = None,
        timestamp: Optional[datetime] = None,
        as_polars: bool = True
    ) -> Union[pl.DataFrame, pa.Table]:
        """Query table with optional time travel.
        
        Args:
            columns: Specific columns to select
            filters: PyArrow compute filters
            version: Specific version for time travel
            timestamp: Specific timestamp for time travel
            as_polars: Return as Polars DataFrame (default) or PyArrow Table
            
        Returns:
            Query results as Polars DataFrame or PyArrow Table
        """
        if not self.exists:
            raise ValueError(f"Table {self.table_name} does not exist")
        
        # Get table reference (potentially at specific version/timestamp)
        table = self._delta_table
        
        if version is not None:
            table = DeltaTable(
                self.uri, 
                version=version,
                storage_options=self.storage_options
            )
            logger.info(f"ðŸ• Time travel query: version {version}")
        elif timestamp is not None:
            # Convert datetime to string format expected by delta-rs
            timestamp_str = timestamp.isoformat() + "Z"
            table = DeltaTable(
                self.uri,
                storage_options=self.storage_options
            )
            # Note: Timestamp-based time travel requires more complex logic
            logger.info(f"ðŸ• Time travel query: timestamp {timestamp}")
        
        # Execute query
        arrow_table = table.to_pyarrow_table(
            columns=columns,
            filters=filters
        )
        
        logger.info(f"ðŸ“Š Query returned {len(arrow_table)} rows")
        
        if as_polars:
            return pl.from_arrow(arrow_table)
        else:
            return arrow_table
    
    def get_history(self) -> pl.DataFrame:
        """Get table history for audit and time travel.
        
        Returns:
            DataFrame with version history
        """
        if not self.exists:
            raise ValueError(f"Table {self.table_name} does not exist")
        
        try:
            # Get history - the format may vary by delta-rs version
            history_data = self._delta_table.history()
            
            # Handle different return formats
            if hasattr(history_data, 'to_pyarrow'):
                # If it has to_pyarrow method
                history_df = pl.from_arrow(history_data.to_pyarrow())
            elif isinstance(history_data, list):
                # If it's a list of dictionaries
                history_df = pl.DataFrame(history_data)
            else:
                # Try to convert directly
                history_df = pl.from_arrow(history_data)
            
            logger.info(f"ðŸ“œ Retrieved {len(history_df)} versions of table history")
            return history_df
            
        except Exception as e:
            logger.warning(f"âš ï¸ Could not retrieve table history: {e}")
            # Return empty DataFrame with expected columns
            return pl.DataFrame({
                "version": [self.version] if self.version is not None else [],
                "timestamp": [],
                "operation": ["CREATE"] if self.version is not None else []
            })
    
    def vacuum(self, retention_hours: int = 168) -> None:
        """Remove old files based on retention policy.
        
        Args:
            retention_hours: Hours to retain (default 7 days)
        """
        if not self.exists:
            raise ValueError(f"Table {self.table_name} does not exist")
        
        logger.info(f"ðŸ§¹ Vacuuming table {self.table_name} (retention: {retention_hours}h)")
        
        # Vacuum old files
        self._delta_table.vacuum(retention_hours=retention_hours)
        
        logger.info("âœ… Vacuum completed")
    
    def optimize(self) -> None:
        """Optimize table by compacting small files.
        
        Note: This requires delta-rs optimization features which may
        not be fully available in the Python bindings yet.
        """
        if not self.exists:
            raise ValueError(f"Table {self.table_name} does not exist")
        
        logger.info(f"âš¡ Optimizing table {self.table_name}")
        
        try:
            # This is a placeholder - full optimization features 
            # may require newer versions of delta-rs
            logger.info("âš ï¸ Optimization features depend on delta-rs version")
            logger.info("âœ… Optimization placeholder completed")
        except Exception as e:
            logger.warning(f"âš ï¸ Optimization not available: {e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """Get table statistics and metadata.
        
        Returns:
            Dictionary with table stats
        """
        if not self.exists:
            return {"exists": False}
        
        # Get basic table info
        stats = {
            "exists": True,
            "table_name": self.table_name,
            "uri": self.uri,
            "version": self.version,
            "schema": str(self.schema),
            "num_columns": len(self.schema.names) if self.schema else 0,
        }
        
        # Try to get row count (may be expensive for large tables)
        try:
            arrow_table = self._delta_table.to_pyarrow_table()
            stats["num_rows"] = len(arrow_table)
        except Exception as e:
            logger.warning(f"Could not get row count: {e}")
            stats["num_rows"] = None
        
        # Get history count
        try:
            history = self.get_history()
            stats["num_versions"] = len(history)
        except Exception:
            stats["num_versions"] = None
        
        return stats
    
    def __repr__(self) -> str:
        """String representation."""
        if self.exists:
            return f"NeuralakeDeltaTable('{self.table_name}', version={self.version})"
        else:
            return f"NeuralakeDeltaTable('{self.table_name}', not_created)"


def create_sample_delta_table(
    table_name: str = "neural_signals",
    num_rows: int = 1000
) -> NeuralakeDeltaTable:
    """Create a sample Delta table with synthetic neural signal data.
    
    Args:
        table_name: Name for the Delta table
        num_rows: Number of sample rows to generate
        
    Returns:
        Configured NeuralakeDeltaTable instance
    """
    import random
    from datetime import datetime, timedelta
    
    logger.info(f"ðŸ§ª Creating sample Delta table: {table_name}")
    
    # Generate synthetic neural signal data
    base_time = datetime.now() - timedelta(hours=1)
    
    data = {
        "timestamp": [base_time + timedelta(milliseconds=i*100) for i in range(num_rows)],
        "neuron_id": [f"N{random.randint(1000, 9999)}" for _ in range(num_rows)],
        "signal_strength": [random.uniform(-1.0, 1.0) for _ in range(num_rows)],
        "frequency_hz": [random.uniform(0.1, 100.0) for _ in range(num_rows)],
        "electrode_position": [f"E{random.randint(1, 64)}" for _ in range(num_rows)],
        "session_id": [f"session_{random.randint(1, 10)}" for _ in range(num_rows)],
    }
    
    # Create Polars DataFrame
    df = pl.DataFrame(data)
    
    # Create Delta table
    delta_table = NeuralakeDeltaTable(table_name)
    delta_table.create_table(df, partition_by=["session_id"])
    
    logger.info(f"âœ… Sample Delta table created with {num_rows} rows")
    
    return delta_table 